# leanConsensus (fka beam chain) call #6: research updates | 3SF (3-slot-finality)

**Prev:** [Call 05](https://github.com/ethereum/pm/blob/master/Breakout-Room-Meetings/leanConsensus/meeting_05.md)

**Meeting Date/Time:** Friday 2025/5/16 at 14:00 UTC

**Meeting Duration:** 1 hour

[GitHub Agenda & Links to Presentations](https://github.com/ethereum/pm/issues/1448)

[Audio/Video of the meeting](https://youtu.be/Eft4K0lGdBo)

Moderator: Justin Drake

Facilitators: Ladislaus von Daniels & Will Corcoran
- Facilitator emails: ladislaus@ethereum.org // will@ethereum.org
- Facilitator telegrams: @ladislaus0x // @corcoranwill


# Table of Contents
- [leanConsensus (fka beam chain) call #6: research updates | 3SF (3-slot-finality)](#leanconsensus-fka-beam-chain-call-6-research-updates--3sf-3-slot-finality)
- [Table of Contents](#table-of-contents)
- [Transcript](#transcript)
  - [Introduction](#introduction)
  - [Gasper \& LMD-GHOST Overview](#gasper--lmd-ghost-overview)
  - [3-Slot-Finality (3SF) Protocol](#3-slot-finality-3sf-protocol)
  - [3SF Mini Prototype](#3sf-mini-prototype)
  - [Q\&A on 3SF and Implementation](#qa-on-3sf-and-implementation)
  - [3SF Finalization Time](#3sf-finalization-time)
  - [3SF Challenges about Rewards](#3sf-challenges-about-rewards)
  - [Q\&A on Implementation](#qa-on-implementation)
  - [Accountable Liveness](#accountable-liveness)
  - [Q\&A on Accountable Liveness](#qa-on-accountable-liveness)
  - [Closing Remarks](#closing-remarks)

# Transcript

## Introduction

**Justin:** Hello and welcome to beam call number six. This call is dedicated to finality specifically 3SF. Today we have five different speakers across four different talks. And I'm also going to give a very quick logistical presentation. So without further ado, let me share my screen.

Okay, so these are links that I've shared quite a few times, but they are useful if you're new to these calls. We advertise the calls on the Ethereum protocol calendar. You will find all sorts of other calls if you're very much interested in Ethereum R&D in this calendar, which is public. There's also a discord with lots of various topics discussed across the devs and the researchers. And finally, these calls are recorded and go on YouTube. And there's also a very handy website, beamroadmap.org, which a community member has built.

So the way that we're organizing these calls is basically in three parts. First, we had a bit of a special call, the social updates call, where the people who had reached out at the very beginning and wanted to contribute were given an opportunity to introduce themselves. And then we had this whole series of calls around research updates of the key topics within the beam chain. And it's quite exciting because we're almost done. This is the penultimate call just before rainbow staking, after which we'll basically have covered the main topics within the beam chain. And it will kind of culminate with beam day in Cannes, just before ICC on June 29th.

And then in the second half of the year in Q3 and 4, we're going to be diving much more into the specs. And the strategy here is to start with so-called subspecs, so specs for the specific submodules within the beam chain. And then towards the end of the year in Q4, putting all of the pieces together and having a full feature complete beam spec for the state transition function. And we're also going to have a special beam day in Buenos Aires, which we're organizing right now. And if you'd like to join beam day, here's the Luma registration. No promises, spaces are limited. But do apply if you will be in Cannes.

Now I also want to give a little bit of a shout out to the sister project in some sense to the beam chain. If the beam chain is kind of this radical upgrade to the consensus layer, if proofs is all about a radical upgrade to the execution layer, where we're snarkifying the EVM, we're radically increasing the gas limit by 100x, 1000x, we're doing things like native rollups which expose the L1 execution, and all sorts of other exciting things. So if you are interested in that topic, there is a dedicated call series and telegram group. And the next call will be on real-time proving. And if you are a ZKVM enjoyer, I would recommend joining this call because there's going to be some big announcements regarding real-time proving.

Now here are today's speakers. We have five different speakers. Luca and Francesco are going to give us a quick sync up and intro on 3SF. Then we're going to have Vitalik talk about an actual proof of concept implementation in Python, 3SF mini. And then Roberto will talk about formal verification. And then Draim will talk about accountable liveness. So yeah, without further ado, let's have Luca and Francesco on the stage.

## Gasper & LMD-GHOST Overview

**Luca:** Thank you Justin. Let me share. Can you all see? Yes. Awesome. Hi everyone. Thank you Justin. Yes, today as Justin already mentioned we are giving you an overview of the theoretical foundation and practical considerations of our proposal for a faster finality protocol for Ethereum. I will first start by giving you an overview of how the currently implemented consensus protocol works, Casper, so that we can build everything organically and then Francesco will start introducing our proposal.

So let me first start with Casper. This is again a very high level overview so that we can all synchronize on the terminology mechanism that will be used then for later for the presentation. So as you might know, Gasper is a proof-of-stake consensus protocol, meaning that nodes in order to participate in the consensus protocol need to put some money in stake becoming validators. So throughout the course of the presentation, I'm assuming that we have n known validators. Of course, observe that this set can grow or shrink over time because we can have new validators joining this set or some leaving, but for the sake of simplicity, let's assume that we have n validators.

The protocol actually comprises two subprotocols or components or modules, however we want to call them, each one with its own properties and each one with its own reasons to be there. One is LMD-GHOST. This is a synchronous consensus protocol that determines the canonical chain, meaning that the chain that we are used to transacting in. Here with synchronous we mean that in order for this protocol to satisfy all the good properties, we need to assume synchrony, meaning that we need to assume that there is a known upper bound on the message exchange among honest validators.

The other subprotocol is Casper FFG. This is a partially synchronous protocol that irrevocably commits the chain outputted by LMD-GHOST or another term used is that it finalizes the chain outputted by LMD-GHOST. What it means is that we basically have this chain that keeps growing output by LMD-GHOST protocol and then we have this Casper FFG that is sort of a gadget that finalizes a prefix of it in a way that basically if asynchronous periods happen or network partition or something that happens, we know that the finalized prefix of this chain will never be reverted. So it's always safe even in case of asynchrony.

Because we have two subprotocols, two protocols, we also have two timescales in which Gasper operates. One is a timescale for LMD-GHOST, which is a slot. A slot is a time unit in which a block is proposed and voted and a collection of 32 slots define an epoch. The epoch is the timescale in which Casper operates. What happens basically is that for every epoch the set of validators is partitioned into 32 disjoint committees, one committee per slot. And because of that in every epoch every validator gets to talk only once.

Okay, so if we consider a slot, what happens is that we have a committee associated to this slot and within this committee a validator is randomly selected to be a proposer. What the proposer does is to create a block and gossip this block around. Basically this block is created that is appended on top of the chain that the proposer deems as valid. What it means with valid will become clear in a couple of slides. It gossips this block around and ideally the other validators within this committee will cast a vote ideally for this block.

In this presentation, I'm always assuming that we have good network conditions. So we have synchrony, honest proposer so that it's also easier to describe how the protocol should work. Of course, there are then corner cases, but they are out of the scope of this very general overview of the protocol. So what happens is that under these conditions we have basically slot after slot a new block votes on it, new block votes on it, etc etc etc. This slot has a duration of 12 seconds and what happens is that over time we have basically a chain which is the chain that I mentioned before, this canonical chain output by LMD-GHOST.

And what I mentioned before is that validators need a way to identify the chain. For example, if I'm a proposer I need a way to identify where to append my block. And we have a function called fork choice function, which in the case of Casper it's also called LMD-GHOST fork choice function, which basically takes as input all the messages received up until a certain point in time and it outputs basically the chain, the valid chain. And the way in which this function identifies this chain is based on all the latest votes, basically the valid chain is the heaviest chain identified by all the latest messages of the latest vote cast by the validators excluding equivocation.

So for example, in this picture, this is the chain. This means that if we are in slot B10, the proposer will see this chain and it will append assuming that this proposer is honest we'll append the block on top of B9, gossip this block around. And also all the other validators within the committee will also evaluate the fork choice function and they will ideally cast a vote for the block that is proposed. Again, the weight of the chain is given by the votes cast by validators because every validator again has some stake so each vote comes with an amount of stake associated with it.

Up until now, I was very generic in describing this voting mechanism, but if you remember at the beginning of this presentation I mentioned that Casper has two subprotocols. One is LMD-GHOST, the other is Casper FFG. Okay, moreover I also mentioned that within a given epoch every validator gets to talk only once. This means that when it's time for a validator to vote to talk, it needs to contribute at the same time to both of the protocols. It means that validators in Gasper participate in the two subprotocols at the same time. And because of that, the voting structure in Gasper is a sort of complicated beast that is made by multiple components.

One component is the component that I just described, meaning this head block component, meaning the vote or the block proposed in the block in the slot. However, there is also a contribution for Casper that needs to be taken into account. And this is itself divided into two subcomponents. One is called source checkpoint and the other is called target checkpoints. Here checkpoints are a special structure, but you can think of them as blocks at specific height of the chain. And generally again, as a sort of textbook protocol, generally these are the first block proposed within an epoch. This means that within a whole epoch all the validators will cast a vote having as a target checkpoint the first block proposed in the epoch. And if at the end of this epoch we are able to find more than two-thirds of votes weighted by stake with the same target, then this target becomes justified.

In the subsequent epoch this justified target will become the source. And if at the end of this second subsequent epoch we are able to find more than two-thirds of votes with the same source, then this source gets finalized. So as you can see, basically in general the source checkpoint is the latest justified checkpoint in the view of a validator and the target is generally speaking the first block proposed in an epoch. Again here I'm being very generic. There are other cases, but just to give you a rough idea of how the protocol generally works.

So we have this idea, we have this mechanism where under full participation, synchrony and all of these good conditions, a block, this prefix of the chain gets finalized every two epochs. This means that currently Gasper takes between 64-95 slots to finalize blocks. And this means that all the time assuming good network conditions, we have a non-finalized prefix that has this kind of size. This means that in case of non-full participation, this non-finalized prefix can grow and grow and grow always more. So in some sense, it exposes also to reorganizations of this non-finalized prefix in case of network partition or asynchrony.

So what we want here is to have a faster way for finalization. Ideally we have this notion of single slot finality, but technically speaking we don't literally need single slot finality. What we want is a protocol that can finalize faster. So Francesco now, after this slide, we start presenting our proposal for a three-slot finality protocol, meaning that ideally under good network conditions etc., we are able to finalize a block within three slots.

Another property that we want is this reorg resilience, meaning that we want that honest proposals remain in the canonical chain wherever assuming synchrony. Right now we do not have this property in the LMD-GHOST component. And here I have another motivation why we were driven to work on these proposals. One was to make protocol faster. The other was also to kind of fix quote unquote the security of the LMD-GHOST protocol, because in the past few years few attacks have been discovered against LMD-GHOST even under good network conditions and etc., that were able to create problems at the safety of the protocol.

So what we did basically was first of all to improve LMD-GHOST by giving some proposals for an alternative component that was able to satisfy this reorg resilience so that honest proposals will always remain in the canonical chain. This means that even if we do not have full participation, we know that under synchrony if an honest proposal is made, it will remain in the canonical chain forever and it will eventually be finalized.

Another property that we might want is this dynamic availability for this component that outputs the canonical chain, meaning that we want to be able to tolerate participants validators going offline, coming back online, even without halting the chain. This doesn't necessarily happen in Ethereum because as you might know we have a sort of incentive scheme for validators to remain online and cast timely votes. But at the same time we also want to be able to tolerate, for example, consensus client crashes as it already happened a couple of years ago where a bug affected couple implementation of the consensus client and 60% of the network went offline for some time. And we want to be able to keep building a chain which together with this reorg resilience property we know that if we have synchrony then everything will be good eventually because then full participation will come back and we will be able again to finalize without having to halt the chain. At most we can halt finality.

And the property that we want that we already have is this accountable safety, meaning that we want to be able in case of safety violation safety inconsistency to identify protocol violators and punish them or slash them, removing some of their stake. So these are the properties that we want and now Francesco will actually get into the more interesting part I guess for this presentation, which is actually our proposal that I mentioned before.

## 3-Slot-Finality (3SF) Protocol

**Francesco:** Francesco, do you want to share? Yeah, I'll just share my own screen. Okay, sure. You have to allow me, I guess. Just thanks. Yeah, so I'll just continue from there.

Yeah, so the proposal that we currently have, as already mentioned, is we call it a three-slot finality protocol in contrast to what we had talked about before for a while, which was this SSF single-slot finality kind of paradigm. So the first question is, you know, why move away from single-slot finality. And there's a few reasons. So the obvious thing is that it requires more voting rounds per slot. It's actually three voting rounds, not two. Like you might know that generally finality requires two voting rounds, but we're in this specific kind of context where we have this dynamic available chain and it imposes a bit different requirements. So actually we think at least that you need really three voting rounds.

And yeah, being able to pipeline this voting rounds means that we have lower block times like we essentially have less voting per block. And this is better for a few reasons. It's better for on-chain markets like there's this whole lever kind of line of reasoning that or like how lever scales with block times. It's better for censorship resistance. We just have more proposers per time. And yeah, it's there is a trade-off however, not everything is better. It's just that we actually get higher time to finality, but not too much. And it's still very very much lower compared to the two-epoch time to finality that we have today. So though there's this trade-off to make, very possibly it might be the right one.

And there's also other reasons. One is that if we have more voting rounds per block, it also means that there is less time to propagate the block compared to the whole slot. So like you could fix, you know, keep fixed the time for block propagation, but now the slot time increases. And block propagation is kind of a sensitive thing that like essentially something that we'd like more of, not less. We'd like to increase block sizes, have more blobs and so on.

And then another thing is that having multiple voting rounds without blocks in between them is a bit tricky from an incentive perspective. It means that you don't have chances to include votes in between voting rounds. And so yeah, this just makes the design of an incentive mechanism more complicated. It's not to say that it's impossible, but at least that's not how the current one works and it seems definitely a bit harder to see how you would do it at least by maintaining the same kind of guarantees that we have now.

Yeah, and motivation aside, this is kind of how the protocol is structured like first starting from the dynamic available component. So basically the replacement for LMD-GHOST. So on top here, you see this like proposed vote proposed like kind of structure, which is essentially just what we have today. I mean, it's not, you know, here maybe the voting part would be not half of the slot because we have vote aggregation today, but it doesn't really matter. The point is there's kind of just two phases like proposing a block and voting. And we basically need to add two new phases, which we call fast confirm and freeze. So kind of add more things to the slot structure.

And yeah, just going through how the slot works. Proposed phase same thing. The voting phase actually also same thing. You would basically just be voting for the fork choice head. So you run the fork choice. This is going to be like a slightly different protocol than LMD-GHOST, but still basically the same as LMD-GHOST. So yeah, just really more like tweaks that kind of allow the protocol to have better properties. And yeah, in the happy path, the thing that you're voting for is just the block that was proposed immediately before.

Then the first new thing is this fast confirm phase. So essentially all that happens here is that if you see a quorum, so two-thirds of the stake from the whole stake. And remember like we are in this kind of dynamically available setting where you might not actually you're not expected to always have all of the votes. But still in this case, like if you do get a quorum, so same kind of similar as you would require for a justification or finality, more or less. You actually consider a block to be confirmed. And this is a notion that we don't quite have today exactly. It's a bit weaker than justification and finality. But essentially it's it means that the block is synchronously safe. So assuming honest majority and synchrony the block it's not supposed to be reorged if you kind of satisfy this condition. And then I'll later explain like why do we even want to have this why you want to add this phase.

Then we have this freeze phase, which essentially means that validators stop adding new votes to their let's say active view. They're still like buffer votes. They don't like just throw them away or not receive them, but they don't kind of actively put them into the votes that they consider for the next time that they run the fork choice. The reason for this and yeah, importantly the proposer does not do this. So the proposer keeps listening let's say actively so it keeps adding votes to its actual the place actually keeps votes that he uses for the fork choice does not just buffer them.

And the reason to do this is that basically the proposer gets a bit of an advantage in the sense that whichever votes were seen by validator at this freeze time the proposer should also see assuming the network is synchronous. And so the proposers should essentially be able to incorporate all of the votes that everyone else uses in its own view. I'm not going to go into details of exactly how the mechanism works, but essentially this allows the proposer to synchronize everyone's view on what it's seeing, which basically allows honest proposers to make sure that other validators vote for their proposals like basically agree with their view of the fork choice and actually vote for what they're proposing. Again this is only for honest proposers so you can't just propose whatever and get other people to agree with you. You can only kind of get a little bit of an advantage to make sure that certain attacks that exist in LMD-GHOST don't affect you. So it's part of this like kind of fixes of LMD-GHOST that Luca alluded to.

And so one question, you know, coming from the picture above this like very simple LMD-GHOST propose vote propose picture is like well now we add these two extra phases like can we just not why do we have to make the slot longer. And it's I mean it's not sure that this to be the case, but it might be that this is the price we have to pay for dynamic availability. So there's definitely like conversations to be had about this price and well two things whether it can be reduced and whether it is worth it. But yeah, in terms of the first part, which is whether it can be reduced. Let's look at them individually.

So this fast confirm phase, the reason why it's there in the first place, it's not just because we just would like faster confirmations like in principle we could just wait for finality. That's kind of the whole point that we're making finality faster. So why do we need this faster confirmation. And yeah, the reason is that basically as far as we know, like all existing dual ledger construction. So all of these things that have an available chain and a finality gadget on top of that, which is exactly the kind of construction that we're dealing with. But not the only one that exists. There's been like there's some literature on this. And basically all of the ones that have good properties that have been shown to be provably secure. They all work with this principle of first confirming a block in the available chain and then try to finalize them. So you don't try to finalize things that are not safe in the available chain.

And yeah, the reason for this is essentially that if something is not safe in the available chain and you try to finalize it, it might be that you succeed and then it causes a reorg later. And I'll explain a bit with some pictures a bit what that looks like. And yeah, if in given if we take this as a given that we need to have this kind of confirmation before trying to finalize something. And so we said this point not clear if we can do this in one slot. So we want to make sure we don't add delays to the finalization pipeline so we want to do it as fast as possible. And it's not clear if we can do it in one slot without this extra delay, at least we don't have a protocol that does this basically without an extra delay. And so this extra phase essentially as for the freeze thing similar story like it's not it's not there's no proof that you need this extra phase.

But what we know is that basically all the existing dynamically available protocols except longest chain so all the ones that have some kind of voting mechanism and I mean longest chain is not interesting here because it has like super long confirmation time so it's really and like it allows reorgs so it's it has like very bad properties. I mean it also has very nice properties in other ways but and it's very simple but it's kind of out of scope of what we're interested in. And yeah, basically all of the ones that have the kind of behavior and properties that we want they do have some kind of proposer synchronization mechanism like this. It's not exactly this one but they always have something along these lines. So at least so far it seems like it possibly an unavoidable thing again not clear. It's possible that someone comes up with a better mechanism or a better protocol without such a mechanism, but so far it seems a bit of a again price of dynamic availability.

And yeah, about the first point, do we need confirmation. You can think of basically this example imagine that we have this situation with like conflicting blocks some honest people vote for one some honest people vote for the other one. And then there's some adversarial votes that are hidden for a while on top we have the block that wins it's this a block it's the head of the chain. It keeps winning but it cannot get justified. So this yellow block is the justified block and it stays the justified block. So it keeps getting 60 votes for a while but it doesn't get justified because it's not 2/3. And then eventually this 40 adversarial votes are revealed and this basically constitutes a justification of B because again here we try to justify something without first confirming it. So the block B wasn't confirmed. I mean it wasn't even canonical ever in any honest validator's view but we still justified it. We still allow these votes to basically form a justification certificate. And so yeah once B is justified it creates a reorg of the whole chain on top. And so yeah under certain conditions like it really makes the whole thing unsafe essentially.

And yeah, so that was for the dynamically available component. And then as Luca said, we have this just this general family constructions is like you take a dynamically available component and then you put like a finality gadget on top. And this is kind of how we construct this three-slot finality protocol. So actually looks very much the same. It's the same structure as before. The only difference is that this voting phase is now actually just like today in Gasper you don't just send a head vote but you send a head vote and an FFG vote. So kind of a vote for both protocols.

And what it looks like and yeah I mean I should say the right the finality gadget that we're using is still basically Casper FFG. So actually there's like essentially very little change there. And yeah, this is essentially what it looks like once you look at I mean it's called three-slot finality so you know we're looking at a three-slot sequence. And yeah I mean here the slot is for some reason missing the confirm phase but yeah pretend that it's there. So yeah these are meant to be the same slots as before but basically what the kind of the path of a block in this protocol looks like is that in the first slot where it's proposed it gets confirmed in the second slot. So everyone votes for it in the second slot, everyone uses it as the FFG target. And so it gets justified. And then in the third slot it's used as the FFG source. And so it gets finalized essentially.

Okay and yeah this is as I mentioned before these three voting rounds that we would otherwise need to compress into one like the confirmation round justification round and finalization round and instead we kind of spread them out over three slots. And yeah and we have this so that that was looking at a single the path of a single block through the protocol but we have in parallel multiple blocks that kind of go through these stages with a kind of off by one. So this is the same as before confirm justify finalize and at the same time the next block would be confirmed while this one is being justified and yeah same essentially afterwards this would be this one would be justified the next one would be confirmed and so on. So in the ideal conditions we're always at the same time doing three things essentially.

And yeah so this I mean this point was a bit high level but more specifically it's worth maybe looking at how exactly do we vote like what are we voting for. And so let's take slot t and say that the latest justified checkpoint is block b at checkpoint at slot s. So this block b and there's a corresponding checkpoint which is justified. So if this is the latest justified, this is where we're starting the fork choice. So how we vote is the head of the chain is the so the thing that we do the head vote for is just the output of the fork choice. So we start from the latest justified. We run this LMD-GHOST like protocol and we then get the thing that we're voting for the source of our vote of our FFG vote is exactly the latest justified checkpoint. So this b at slot s.

And then the thing that's a bit different in today than in like kind of regular Casper FFG is what the target is so the target would be a block T at a slot T at well slot T is the current slot. But it kind of there's a bit of a difference in how we determine what the block T is. So as I said before it's meant to be the target is meant to be confirmed. So this is something that we're basically inputting into the justification and finalization pipeline it's kind of the entry point towards being justified. And so we want this to be confirmed. The best case would be basically that we try to vote for the highest confirmed block which in the really best case would be the block from the slot before. So kind of going back to here something gets confirmed and then immediately afterwards we try to justify it. So it's in the next slot it becomes the target. So yeah it basically would be this like if we're in this slot and then we use this as the target if it was confirmed.

But actually we only do this if we are in the happy case where basically the latest justified is recent. It's really something that was justified in the previous slot. So this s is t minus one. And if that's not the case we're kind of in a non as great case where there's not a recent justification. Then we basically make the target be either b or the k-deep block so we kind of go deeper in the chain and find some block that we are sure is safe. And yeah I mean if this block is after b we take that block otherwise we will take the latest justified itself. So for example in this case we would take this block here so kind of a k or kappa from the beginning of the chain and the idea here the idea here is basically that this block is so once we're in this case something bad is happening where the latest justified is not very recent. There's a potential for some new justification kind of in between that can cause reorgs. There's this concept of bouncing attacks that I can't don't have time to get into but it's kind of a tricky another tricky thing of this merging of finality gadget and an available chain.

And can once we're in this potentially tricky situation we want to make sure that we use a target that's that everyone can agree upon. And so the nice thing here is that if anyone that agrees on what the head of the chain is would also agree on what this kappa-deep block is. So if you if you agree that this is the head of the chain you agree that this is the block k-deep. And so you would also agree on what the target is and this means that the justification is actually guaranteed in this case that if we're in an honest slot in particular then we're sure that in this bad case we can actually fix things kind of save things and make progress and justify a new block. And in this case we actually guarantee that we get finality in three slots which is a bit counterintuitive because as I said this supposedly is the bad case but actually in this bad case we can guarantee that if it's an honest slot it will actually be finalized for sure in three slots.

And yeah with this I think I'll leave you there. There's more that Roberto will talk about but in between I think Vitalik wanted to talk about 3SF mini prototype that he's been working on.

## 3SF Mini Prototype

**Vitalik:** Yes, hello guys. Okay let me quickly share the GitHub. There we go. Okay, so this is just a project that I worked on for like just fairly recently which is basically just a very simple and minimal implementation of three-slot finality in Python. And so it's in GitHub Ethereum research and then in the 3SF-mini directory and the goal of this is basically to try to like present a concrete implementable version of the three-slot finality consensus logic and then put that in an environment where we can actually runs you can actually test it and you can actually get to see like what a live network out of these kinds of things is able to look like and you're able to see all of the core pieces of the protocol running.

So maybe just go through some of the files here right so this is like the whole thing is basically about like 400 lines. I think like 500 if you include the testing code but so this is consensus. So this is basically the equivalent of the file that would go into you know the like beacon chain specs and so we have a state we have votes we have blocks everything is getting hashed and then the core functions here that are interesting are one is the function for getting the fork choice head. Which basically start at genesis by default, but then actually generally gets called with the root being the latest justified block and then from there it identifies what the latest votes are and then going through the latest votes basically figure out what the vote weights are and then you do this kind of walk going from the root all the way up to the tip where you pick the highest weighted parent at each step.

And it also has this min score parameter that basically allows you to stop progressing as soon as the weight drops below some particular threshold and the goal of this is to just make it very natural and easy to implement the optimized targeting mechanism that Francesco talked about. So one other interesting bit that's in here that I think is a sort of original research contribution and that like so far is not part has not been part of discussions but like this is my invitation for people to take the idea seriously and either rip it apart and show why it's insecure or ideally show why it works and this is the quadratic backoff mechanism.

And this is basically something that I discovered from simulations is that if you push the peer-to-peer latency up to the point where it's too high for the chain to converge really nicely so like I've been running this with the peer-to-peer latency parameter being I mean we can actually go in here and see what the default setting is you go into test test P2P and as you can see the latency is bounded above by 2.5 times the slot duration so I'm literally testing it at sort of 10 times provably safe parameters and the thing that I notice is that like there are situations where the chain just kind of stops converging and nothing breaks in an irreversible way but basically once latency goes above a certain level it's the challenge is that it's just hard to get this like nice clean three step in a row thing of like a block becoming a safe target and then being justified and then being finalized.

And so the mechanism here is we say that there's only a subset of slots that are justifiable and the slots are basically any slot up to five after the last finalized one and then if you go greater than five then it's sort of backing off with a perfect square relationship right so like you can finalize the slot nine slots after and 16 slots and 25 slots and so on and then also just here I added the oblong numbers so this is basically the numbers halfway between perfect squares because that's like empirically better but nothing in between.

And this is interesting because it lets you say that you finalize without needing two things to justify one right after the other instead you basically need to have your justification slots where in the range in between them there aren't any other justifiable slots right and so the kind of 30,000 foot explanation of this right is that you can turn any protocol that is safe under asynchrony and converges when synchrony recovers into a protocol that can that finalizes under partial synchrony in the sense of under some delta where you don't know the delta and the way you do it is you basically search and replace time with a square root of time right because as time increases the deltas in square root of time just kind of naturally shrink and shrink and so virtual time just kind of shrink to zero right so like one just like one interesting tidbit here then the way in the peer-to-peer file this is the other thing we have a this is the equivalent of the honest validator implementation and the honest validator implementation so it just tracks the chain and tracks known votes it tracks all the stuff that you'd expect it to track and then the most important loop is this guy right so this basically shows the logic of what you do at all four different parts of a slot right and so you have four subslots so at time t equals zero you propose a block and then you have a view merge mechanism so you accept attestations from the newest block from the most recent block but then or attestations that you got from over here but then generally the time delay to get other people's attestations is like this right so then over here we have and then at time t equals a quarter we vote and then at time two quarters you compute and save the safe target right and then there's a function for proposing the block and for proposing the block we choose the parent based on the safe target and then for voting we choose safe target and then we do the like backoff based mechanism where if there isn't like basically if the most recent block isn't safe then like you walk backwards a bit and then you walk backwards to either the justifiable slot or some maximum I set the max to three here you can set it to whatever.

And you make a vote you submit it to the network and you have code over here for receiving blocks receiving votes from other people so pretty basic stuff and then this is just a very basic bare bones peer-to-peer network simulator so you can have many peers they can send messages and then they can recover receive different messages so a bunch and then over here we have the code that actually runs the graph stuff so I wonder if we can actually do a thing do programming research 3SF-mini try new share on this guy and then basically if you do like Python the test P2P then you know the thing should run and then okay well it's unfortunately not actually showing the thing but here I'll wait for it to run and then there's like a nice Matplotlib live view of like what the network looks like almost done almost done crap sorry it just stopped okay here I'll click click figure one share let's see there we go okay there you see it Justin yes perfect yes okay perfect see and then the thing is growing and so what we see here right is like you saw during the first two-thirds of the simulation the network latency was 10 times what the algorithm is rated for and so there were like a lot of forking but you saw the justified and finalized one like still make progress the chain still remains stable and then after the two-thirds window latency dropped to zero and then the chain just like completely stabilized very quickly so there we go that's the code so again Ethereum GitHub Ethereum research and then it's the 3SF-mini directory right in the top level of that just encourage people to take a look at the code like pour through it carefully make sure it accurately represents the algorithm if it doesn't complain to me you know I welcome complaints and also again invitation to explore the backoff thing because I expect it will actually be quite important in making the thing this whole algorithm work really well under high latency situations and just try different variations and just a really good playground to do different things and you know potentially even use this as like the base of any spec work that happens so thank you guys.

## Q&A on 3SF and Implementation

**Justin:** Thank you Vitalik has to board a plane very very soon so any questions for him now is a good time to ask feel free to unmute or ask in the chat or raise your hand.

I mean one kind of social question that I have or meta question is how much time did it take you to build this and how much of your time are you planning to spend on research and the beam chain going forward.

**Vitalik:** Yeah I mean so this thing to remember I think it took like a few days I mean it was done like over the course of about one and a half weeks but very interspersed with a bunch of other work so I mean if I had to like retroactively estimate and like turn it into like a lawyer billing hours I would probably say 5 to 10. And then I mean in general like I'm definitely happy to continue to be in like be more involved in different places and I think you know both this the beam chain and all this or I guess you know lean Ethereum if we're calling it that and all these projects you know they are really important to me so you'll definitely see me back.

**Justin:** Yay I mean just as a historical note you know something like half a decade ago Vitalik wrote the initial draft of the beacon chain and he kind of whipped it up in a week and that was what we polished from that point onwards so having Vitalik involved is a sigh of relief at least for me. Any other questions before we let Vitalik board his plane. Camille.

**Camille:** Just a quick one is this research of three-slot finalities kind of orthogonal to orbit SSF or is completely different direction like.

**Vitalik:** Good question it is orthogonal so you might notice 3SF-mini as written it's technically in one of those like evil banker consortium chains like it just says here are the 10 validators and they make the blocks so the idea is that you're able to like plug in whatever validator set mechanism you want the one thing that would need to be added to this code to make it kind of more comprehensive as the proof-of-stake part of the beacon you know the chain would be yeah the validator set changes and the logic for like syncing through many validator set changes and then of course like inactivity leaks and economics but the difference between kind of the you know like 4096 validators and and that's it versus orbit is something that you can kind of blackbox and put into that framework so from the perspective of this logic it just looks like validator sets that have different rules for changing.

**Justin:** Okay well thank you guys so good luck with the rest of your call. Thanks Vitalik. I guess we can also open it up for questions on the first two speakers Luca and Francesco.

One question that I have for Francesco is it seems that there's a lot of subtleties involved there's all these attacks that are like totally non-trivial that we have to worry about and so my question is to what extent is the protocol that you proposed provably secure.

**Francesco:** Yeah there's definitely a lot of subtleties I think it's hard to deny but I the so the protocol that I am kind of talking about today is maybe one could say a simplified version of something that a paper has been written about. I think the protocol that the actual protocol that the paper's been written about which is more complicated but in some way but yeah anyway that protocol I would say I'm very confident is probably secure just because there's been like a lot of thought over years around like there's been you know different evolution of things like first like this SSF protocol and then that kind of turned into this other this first version of 3SF. So a lot of these attacks that I'm talking about they really are attacks that are relevant to the current version of LMD-GHOST and how it relates to Casper FFG and I mean they still point to there being you know many non-trivial things that you need to keep in mind but we have like a clear view of how these attacks are resolved and like just why yeah why basically there's no reason to worry about them in the current protocol and also besides that it's not I'm not just saying that I'm confident that it's secure because we think that we've resolved these attacks like it's not just like a whack-a-mole kind of thing but actually we have like proofs of security and I think the security proofs are actually very like it's actually a lot easier to think about it in terms of security proofs than in terms of the original attacks you can kind of just ignore all of the original attacks and just look at why the protocol is secure and in some sense it's actually simpler though it's also nice to then go and figure out like you know how did this like where does it show up that these attacks were actually resolved and kind of we have both of the views I think.

Then yeah specifically about the protocol that I'm talking about now this maybe I'm like slightly less confident about just because it's a bit more recent that we've like made some simplifications which I think were necessary for like implementation complexity reasons I mean spec complexity just complexity in general so there's some like relaxation of some things essentially compared to what's in the paper. For example this last slide that I had about the two different mechanisms for choosing what a target is but yeah I'm still quite like you know very sure that this is kind of safe in all the well you know live and safe and so on. I think it's more I guess that it's still an evolving process and like I think as we're we've been like more actively writing like a sort of pseudo spec with this simplified version of the protocol and there's often little tweaks that we want to make because something is just would be nicer to simplify it for like again implementation complexity reasons like often it's something around what are we tracking in the state and like wanting to reduce that and so yeah as we make this like little tweaks then always there's a little bit of lowering of confidence you need to like reconvince yourself that actually the tweak doesn't break any of the previous reasoning but I think yeah overall it's not too bad.

Okay got it so like putting my optimistic hat on for example Vitalik's new idea of the quadratic backoff because we have this mental model of what the attacks are and what security proofs are we can just adapt the proof to all the tweaks.

**Justin:** I guess my other question is do you feel like Vitalik's implementation to the extent that you've you know you only have limited knowledge of the details if you haven't looked at it carefully how closely do you feel that matches your simplified version of 3SF.

**Francesco:** So at first it didn't but then it was more of like a really simplified version of 3SF but then like we had some rounds of like I looked at it at first and I kind of mentioned some of the things that were missing like whatever and like as far as I can tell Vitalik added like all of the things that we discussed. So I think right now it's quite like yeah quite close I haven't looked really like very in depth at I don't know for example this target mechanism I honestly don't remember if I'm pretty sure he does have the fast confirmation thing I don't remember if he has the kind of other case of like resorting to the k-deep block but yeah I think most of it is actually what the simplified kind of last version is.

**Justin:** Okay that's great to hear that you've been working with him on this. Any further questions before we move on to Roberto.

## 3SF Finalization Time

**Roberto:** Okay Roberto the floor is yours. Good thank you so what I want to start with is expanding on the actual finalization time of 3SF as kind of Francesco with reference to the protocol that Francesco presented the guarantee that we have in terms of finalization is a guarantee is that if you have two consecutive slots with honest proposals the block proposed by the first proposal will be finalized within three slots.

Now the question is what if the second proposer is not honest. Well in this case actually things are not that bad. It's what's going to happen is the guarantee that we have is that the block will be finalized three slots after the first pair of two consecutive honest proposals. However we still have this guarantee that the block proposed by the honest proposal initially is not going to be reorged out. So potentially if the second proposer is not honest there is a potential delay in finalization compared to this three slot. However there are conditions like the one Francesco mentioned before where the greatest justified is not from the previous slot but from other slot where the protocol Francesco presented actually guarantees finalization in three slots even though the second proposal is not honest.

We as some people know we have written a theoretical paper and this theoretical paper actually present something that is that allows finalization of a block in three slots regardless of whether the second proposer is honest. So we go from the first picture to the one at the bottom. Now problem with this theoretical protocol so we know how we can get rid of this second requirement is that introduces quite heavy change in how justifications are computed. First of all we allow to justify more than one checkpoint per block as you can see in the middle and essentially now in this picture the red arrows are the FFG votes and if you have an FFG vote that kind of surrounds a block or a checkpoint we justify that checkpoint. I don't want to go into details because it's quite complicated and that's actually what I want to communicate with this slide is that there is a lot of complexity in this extended justification rule.

And so the question really is it worth it? Like is it worth to have this complexity to put time and effort also this having to deal with more checkpoints is likely to require significant more data to be stored in the beacon state. So there's a question here whether having this additional guarantee that regardless whether the second proposer is honest we finalize in three slots is worth basically going down this route or not. And again with protocol that Francesco presented is not that if the second proposal is not honest then we don't finalize in three slots we just don't have the guarantee that that will happen. So this is a question for the community or that would be nice to get a feel about.

Now I'm going to move into discussing some implementation consideration that come up when we consider 3SF regardless of which protocol the one that Francesco presented or this second one with a slide with a change in the justification rule. The first thing I want to talk about is about justification transferability and this is something we don't have today. This is because today the weight that is associated to an FFG vote depends on the chain where it is included. So if you look at this example we have an FFG vote from checkpoint A to checkpoint BM and if it's included in the first in the chain of block in if it is included in block E the weight is W1 if it's included in block G the weight can be different and this is because we use the balances at the point where the vote is included.

And this creates problems so the problem this is creates is that because votes can have different weights based on where on the block where they're included there are justifications that sorry there are checkpoints that can be justified on one branch but perhaps not on another. So if you look at this example let's say there is a checkpoint BM that is justified on the bottom chain but is not justifiable on the top chain. Now let's say that this block this checkpoint BM is actually the greatest justified what we have to do we have to filter out the top branch because in the top branch we can't justify BM and therefore we can't continue in the branch we'll never be able to justify anything new.

Now the problem with this is that perhaps the top branch is the branch that LMD-GHOST has chosen based on the head vote is actually the canonical chain so what ends up happening is that actually this causes a reorg of the canonical chain which is clearly not as Luca has mentioned in the properties that we want this is not something that we want at all. The solution to this is to make the weight associated with an FFG vote based on the chain or based on the target block so in this case the idea is to make the weight based only on the target block B so it doesn't matter where you include this vote if you include it in E or if you include it in G it will always have the same weight associated to it. In this way we can transfer we can move justification from one chain to another and because of this we don't need to have that filtering mechanism that I explained before that can cause potential reorgs.

Now with these techniques of course we have an increase in data that we need to keep track of because now we can't use the current balances when evaluating an FFG vote we need to go back to the balances according to the target block. So one solution is to introduce snapshots so the idea the overall high level idea is that we take snapshot at given intervals like every 100 slots. And what is going to happen if we have an FFG vote like the one at the bottom where the target is block B150 we don't look at the balances in block B150 but at the balances according to the snapshot just before in this case the one the snapshot S2 which is which corresponds to the balances in block B100.

The advantage of this solution is that we do reduce the amount of data that we need to keep track of in order to be able to process FFG votes. Now of course we reduce it but we do not cap it as potentially as the chain progresses the number of snapshots that we might need to keep track of progresses as well. So one solution is to have a snapshot window basically we give a timeline after which snapshots expire and if you have an FFG vote that requires an expired snapshot this FFG vote is invalid.

The advantage of this solution we have less information to store in the beacon state but however because of this expiry we need this this introduces new opportunity for reorg in a way similar to the one I showed before that we get rid of by using the target to determine the weights this can introduce new reorg opportunity they're not that bad though because they actually happen only if the network is there is high latency or there is asynchrony and they have a lot of consecutive dishonest proposals.

There is potentially another solution which is that if an FFG vote requires an expired snapshot then the proposer must provide a Merkle based proof of the balance that needs to be used and we can do this because we have historical roots in the beacon state so this is something that can be done. The great thing about this is that it doesn't introduce new reorg opportunity but it adds protocol complexity and also testing complexity because now we have two different ways to create a justification one that requires the proof one that doesn't and the one that requires the proof is probably very rarely used so if there is a bug it will take long time to discover it and perhaps the bug comes out at the wrong time and also there is an extra burden in creating this Merkle proof if the snapshot required is expired.

Now connected to this concept of the snapshot window creating potential reorg opportunities we also thought about potentially introducing a max reorg depth. The idea here is that we have parameter D or max depth as you want to call it and whatever is before we are never going to revert it even though it's not finalized we never revert it. So as an example let's say that you're in this situation where we have the greatest justified GJ and then we receive a new branch with a greater justified checkpoint GJ prime. Because this is beyond the max depth we are not going we if we introduce the rule this rule we will not reorg from branch B to the branch where including GJ prime so which is what without the max depth we will do.

Now the problem with this solution is that can create split views because it's possible that for example half of the validators were on the branch at the top and they don't reorg so they stay the branch at the top perhaps half of the honest validators see GJ prime first and so they're locked on that branch so we can get into this view where we might be we need to recover from it using social recovery. So there's a question that you know there's a benefit we know that we can automatically reorg beyond a certain depth but then we do need this can create a split view scenario where we don't we need social recovery to recover so there is a question whether this is something worth doing or not.

Next topic I want to talk about very quickly is about inactivity leaks so with 3SF like today we want to ensure that the chain doesn't lose liveness even if more than one-third of the validators go offline forever so we do need a way to leak the inactive validators' stake if this happens so the finalization can start again and I think Joachim the next presentation by Joachim is connected to this.

Next topic is about committee management which was mentioned before so committee protocols like for example orbit are a way to allow to have a very large validator set but to contain the number of validators that are actually voting in a given slot. So this introduces committees so subsets of the overall validator set and a way to move from one committee to the next so the way we have thought about implementing such committee rotation committee change in the 3SF protocol at high level is to change committee whenever that committee finalizes a block so if you take a look at the picture at the bottom initially we have committee N then committee N finalizes block B after delay K we need this delay K to ensure that all honest validators can actually see this finalization they all have the same view what the actual active committee is so after this delay then the next committee committee N plus one starts then when committee N plus one finalizes a new block we move to committee N plus 2 and so on.

Now this is a very high level there are a lot of details in how to make this secure and we need to add additional slashing rule and overall say it adds a lot of complexity to the protocol so it's something that I think from a theoretical level we are quite confident can be done but whether this can be implemented efficiently that's currently an open question.

## 3SF Challenges about Rewards

**Francesco:** Finally I hand over to Francesco to cover this last slide. Yeah this is almost like a more of a just quickly calling out this not open question but just I guess something that it would be nice for more people to think about and yeah where there's maybe like expertise that's not necessarily ours.

Yeah so the rewards are a bit tricky I think for a few reasons but one particular one that's not obvious at first is that during normal operations there isn't like a correct target something that you can objectively say like this is the thing that people should be voting for. And this is essentially because fast confirmation is basically not objective this is something time independent so different people could have seen different boots at different times and this could have led them to confirm something different from each other. So even when you focus on a specific chain you can that chain cannot be sure of what is the right thing to vote for. Whereas today from a chain perspective it's clear that there's a correct target there's a correct source in our case that's not exactly the case.

And so one possible solution is to basically take justification as the only signal of something have been done correctly at least as far as the target so only basically reward validators that actually contributed to a justification. And one other good thing about this would be that it simplifies what needs to be tracked in the state. And but then yeah but there's questions even if you did decide that okay this is the right thing to do there's like questions around how do you do you want to do it. You could reward only the first justification or you could reward like anyone that contributes to justification for example if you don't want to kind of make sure that you can still reward votes that get included later so that you don't create like ways to do discouragement attacks or basically just create like griefing vectors of various kinds and but yeah all of these things also interact with implementation complexity and like you know what things you need to track track for how many kind of ongoing justification during periods of finality so there's a lot of it's definitely more complex than on the current chain because on the current chain there's only two possible targets at any given time there's only like the current epoch and then previous epoch whereas here in principle there could be many possible justifications that are going on at the same time and here also like there's something to think about with how this intersect with Vitalik's backoff proposal because actually that in principle could simplify things it could just reduce the space of things that we need to keep track of even if we do want to have a more basically comprehensive way of tracking things and rewarding voters.

And yeah a little thing about this is that of course during the inactivity leak period you don't expect to have justifications and so there's you can't quite use this rule to reward people but actually things get easier during the activity leak strangely because we during the activity leak we can just say that we tell people not to vote based on that on the this fast confirm target but to always choose the kind of safe conservative one like the for example the k-deep block and so in that case there actually is an objective target so where if you voted correctly for the head that also implies you've correctly voted for the target so at least that part gets easier but yeah this is more just like describing some almost like vague thoughts that we've had about this and I feel like there's a lot to think about here that we haven't done at this point and yeah it would be definitely great for I think Anders is on the call people like you or I mean many other people that have expertise on this to give this a thought at some point and yeah with that I guess I'll leave you to Joachim.

## Q&A on Implementation

**Justin:** Any questions for Roberto before we move to Joachim. I have one quick question by the way I apologize for kind of saying that your talk was about formal verification it's actually not it's about these practical considerations I guess my question is has the formal verification effort been postponed until we tie off all of these loose ends from a practical standpoint. And how do you feel in terms of timelines for closing off all of these practical considerations.

**Roberto:** Yeah so formal verification has yeah that has been postponed until we sort out these things basically to the point where we have a spec that we are happy with and that we think has addressed most of the if not all of the concerns. Terms of timeline that's a difficult question I might take the fifth amendment on this one I don't know like it's hard to say I don't know I say we are working through some optimization at the moment were beating manual proofs say few months say 3 months I don't know I hate to give a time but yeah Francesco Luca feel free please feel free to jump in and yeah if you have different opinion.

**Francesco:** Does Vitalik's implementation have a lot of these loose ends untied? Uh I haven't taken close look at it I don't think it has but I don't think so. I think on the tracking of things which like is one of the things that we're generally trying to figure out the the best way to do and like that ends up usually causing that or like is one of the things that has caused some of these like needing to tweak things or like wanting to tweak things. I think maybe if I remember correctly Vitalik's implementation is simple in the sense that I think it's just tracking all the things that it could be tracking like all the checkpoints and so yeah I don't know if it has the snapshot or like these other kind of logic that Roberto was talking about but I should double check but yeah I think that's the area that where I think like some decisions should be made at some point soon and other than that I think yeah more like things are not so like things like on top like rewards and so on are a bit more up in the air but but also they end up kind of feeding back into the into how the protocol is structured so it's there's yeah if sometimes it feels like okay the protocol is done but then like something that you build on top requires you to make changes to it so that's where we're at I guess.

**Justin:** Okay got it thank you. Joachim the floor is yours.

## Accountable Liveness

**Dr. Kim (Joachim):** Okay everybody sees my screen. Yes perfect thanks for having me good to meet you all I'm going to be talking about a new paper of ours titled Accountable Liveness this is joint work with Andy Lewis-Pye with Tim Roughgarden and with Luca Zanolini who spoke earlier and if you're interested to know more I highly encourage you to check out the paper it's on e-print on this link I will also have that in the end and the introduction is about like three pages and fairly self-contained explains kind of the intuition of what I'm about to tell you and so I very much encourage you to go check that out before I start I have to give you important disclaimers none of which what I'm about to say is financial advice only for it's only for academic and informational purposes.

So here's the thing right so if we think about accountability for blockchain consensus there's a solved problem which is if a blockchain suffers a double spend who is to blame the answer is for PBFT style protocols and that captures things like Tendermint or Casper FFG like what we have on Ethereum roughly the answer is nodes that have voted for two inconsistent blocks. And that's what we use in Ethereum for the slashing mechanism. Here's an unsolved problem: If a blockchain stalls who is to blame. In Ethereum we have a mechanism for something like this the inactivity leak which is however only a heuristic and in this work we give a description sort of of the security property we would want to have of a mechanism like this we call that accountable liveness and we sort of develop the foundations of that concept so we explore when is it possible and in particular also when it is when is it not possible to achieve accountable liveness and how can you do it using what protocol techniques.

So here's my 20-second consensus slide. Atomic broadcast consensus is about the following right we have transactions that get input to our n validators that run the protocol or nodes and these nodes then output logs and the job of the blockchain really is to produce an ordering of the transactions on the chain. This problem is hard because the network is not perfect. There's message delay whenever validators sent each other messages and for the purposes of this talk I'm mostly interested in something called partial synchrony. If you haven't heard about this it's not that important if you have heard about it remember there's this global stabilization time and there's a delay upper bound delta that holds after sort of the period of network asynchrony over. And the problem is also hard because we have to make the assumption that a certain number f of our nodes is malicious.

And in this setting we want to design a protocol which is essentially an ordering protocol that has two security properties one is called safety which basically says if the adversary is not too strong like for example the adversary is less than a third of all the nodes then for every two nodes p and p prime and every two points in time t and t prime the logs are basically consistent so either one is a prefix of the other or vice versa. That's one important property and the other important property you may have also heard of is called liveness which is if the adversary is not too strong then for every transaction and every node you know shortly after like for every point in time shortly after this transaction was submitted to the chain and we've given the protocol time to confirm this transaction that transaction should actually be in the output log of every honest node.

And accountable safety is a strengthening of this safety property sort of turning the argument around and saying okay you know what happens if the adversary is stronger than this than this resilience of n over three right and accountable safety gives the foundation for cryptoeconomic security and it basically turns the argument around and says okay I you know I want the following property suppose it's not the case that everybody always has consistent output logs. In other words there is some inconsistency then I want to be able to provably identify a certain fraction of nodes as Byzantine.

And this is sort of the you know the state of affairs up until now and in some sense what we are doing and that's where the name accountable liveness comes from is we're trying to do sort of the same trick to the liveness property right we want to turn this argument here around and say suppose it's the case that a transaction is not confirmed within time then we can provably identify a bunch of Byzantine nodes and we'll have to revisit sort of what number it is whether it's n over three but you know that's sort of the gist right.

So for accountable safety and this has been studied you know comprehensively in the last 10 years basically going back to 2007-2009 are the earliest papers I'm aware of accountable safety is this property that when there is a safety violation we want to have a smoking gun implicating Byzantine nodes right. It's important to keep in mind right the non-trivial regime here is when the adversary is stronger than n over 3 because otherwise we have the safety property right this is just the strengthening of the safety property so if the adversary is less than n over 3 we have the safety property anyway so there are no safety violations so then accountability is sort of trivial. So interesting here is when f is greater than n over 3 and the way we get accountable safety is roughly right through some sort of a blaming function where if you're given message histories of two honest nodes with inconsistent output logs then you're able to identify a large set of Byzantine nodes and how do you do that intuitively you output nodes that you're catching voting inconsistently. And it's important and this is preserved by this mechanism that no honest node should ever be falsely accused and you want to make sure that you whenever there is a safety violation you can actually identify Byzantine nodes and you can then go and remove them or slash them or whatever right the question of how you actually affect slashing and actually make it happen and sort of clean up the validator set and kind of recover from a validator set that has less adversaries is outside the scope of what I'm talking about here but if you want to know more there's two recent papers by Lewis-Pye and Roughgarden where you can learn more.

So for accountable liveness we want something similar right we want if there's a liveness violation there should be a smoking gun implicating Byzantine nodes again the non-trivial regime is if the adversary is greater than n over 3 because otherwise there are no liveness violations to begin with. And we'll try to our goal will be to base this on something similar to this blaming function right where if you're given message histories of at least all the honest nodes then you want to be able to output a large set of Byzantine nodes so the idea here is right again we want the property that honest nodes should never be falsely accused and Byzantine nodes should be identified whenever there's a liveness violation so that we can remove or slash or leak them whatever you want to call it and intuitively here we have to change how this blaming function works the idea is we want to output nodes that we catch not voting for blocks that they should have voted for. That's kind of the intuition.

The TLDR of this property is that accountable liveness is harder to achieve than accountable safety. Why is that so well you may guess that that is so because in some sense for accountable liveness you need to prove the absence of messages that the node was supposed to send absence of expected messages rather than the presence of unexpected you know too many or inconsistent messages. But you know an unreliable network by itself may be to blame for liveness violations and not Byzantine nodes that's in contrast to safety violations right safety violations come from conflicting votes that are signed by the same node and no matter what the network does at least that node should have had you know should be self-consistent with the honest protocol.

And the other aspect of this is that you know we somehow then have to rely on like you know bringing honest like bringing the views together and sort of figuring out who saw what at what point in time in order to blame people and find out who is actually guilty. And because of that process Byzantine nodes can be can frame honest nodes which is also not the case in accountable safety where you know vote where the conviction is basically based on signed votes and nobody can forge those.

Okay so that's roughly intuition at this point but we can make that precise right accountable safety has two very good properties one is that it can be added to optimally resilient partially synchronous protocols without any new assumptions for example on message delays whereas for accountable liveness we prove this theorem in the paper that no optimally resilient protocol can be accountably live if the network is in some intuitive sense more often asynchronous than synchronous. And in particular then also not under partial synchrony and what exactly this you know more often asynchronous than synchronous means that has a technical definition to make all of this precise to get an actual theorem which you can check out in the paper but you know the intuition is that over prolonged periods of time sort of if the network is more often asynchronous than synchronous then you cannot get accountable liveness so that sort of justifies this intuition of unreliable network maybe to blame for liveness violations and so if the network is just too bad then there isn't that much hope.

And then the other nice property about accountable safety is that it can be provided no matter how many nodes are Byzantine right even if almost everybody is Byzantine the adversary cannot evade being held to account. Whereas in the case of accountable liveness we prove a second theorem which is that no protocol can simultaneously provide safety under partial synchrony even if there's basically no adversary and accountable liveness when sort of the majority of the nodes is adversarial even if the network is synchronous. And that sort of you know is a formal natty version of the statement that Byzantine nodes can frame honest nodes and yeah based on that you may expect this accountable liveness to not work under dishonest majority.

So it's actually true that accountable liveness is harder than accountable safety. And those two impossibility results what's kind of the coolest thing that we could possibly hope for well we know that there's not much hope to get accountable liveness for f greater than n over 3 if we are in minority synchronous executions or for f greater than n over 2 even if there is synchrony right and the problem is vacuous if we only consider f less than n over 3 in sort of majority synchronous executions. So the best we can sort of hope to achieve is that we can get accountable liveness if f is less than n over 2 so if we are majority honest and we are under majority synchronous executions and the main result of the paper is that this is in fact the case. So we have a protocol that has this property.

More precisely the main result of the paper is that we can augment a protocol like Tendermint but the same construction applies to things like FFG in such a way that as usual if f is less than n over 3 we get a safe and live protocol under partial synchrony and we add an additional functionality which is as long as f is less than n over 2 then we can get accountable liveness in majority synchronous executions.

I will try and give you sort of a high-level idea of how this protocol works. It's you know I make a bunch of simplifications you can find the full version in the paper but yeah we'll see how it goes. So we start from a protocol like Tendermint recall in Tendermint we have you know views like the protocol proceeds through a sequence of views and every view has the same structure. This is similar to these phases that Francesco was talking about earlier at the beginning all validators sort of send their latest state to the leader of this view the leader then makes a proposal and then we have two rounds of voting until we eventually reach confirmation. That's the idea of Tendermint and in order to make Tendermint accountably live we add logic to each view. Namely we make all the nodes rebroadcast all the messages that they've received and monitor messages that they see as being sent by other nodes and if a node P observes that a node Q has failed to send a certain message think in particular a vote that it should have sent under the assumption of synchrony then we say P blames Q in that view V.

And then eventually if there is a liveness violation for example nodes exchange information about who blamed whom and at what point in time and then we do some sort of accounting of all of this blame in order to figure out who is actually guilty who we actually want to hold accountable for this. So remember you know there are a bunch of reasons why why a Tendermint view may fail to confirm a transaction it could be because of asynchrony it could be because there are just a bunch of Byzantine nodes not voting basically for the proposal or there could be some like bunny shenanigans like a Byzantine leader but I want to make it a little simpler we have a technique in the paper to sort of extend it to all those cases but for now let's ignore three right and let's focus on sort of these two options right either we're in asynchrony or we are under synchrony but somehow there is still no confirmed transaction we're under synchrony and we have an honest leader and for some reason there's still no confirmed transaction then this must be because somebody has been withholding votes right.

So suppose Tendermint fails to confirm transactions either we're in a synchronous view this happens more often than asynchrony. Now it's interesting in a synchronous view we can the protocol is built in such a way that honest nodes do not blame each other right they basically always know there's an honest leader all the honest nodes will vote for the proposal of the leader so nobody is sort of missing a message and so nobody no honest node blames any other honest node but if we don't get confirmation right there's n over 3 votes sort of missing right and because these votes are missing there you know all honest nodes will detect that that they have not been sent and they will be blaming n over 3 Byzantine nodes by all the majority like by all the honest nodes which is the majority. So those Byzantine nodes are majority blamed if we're in an asynchronous view then all bets are off but luckily that that happens much less like that happens less often than synchrony because we've made the assumption that we are in majority synchronous executions.

Okay good now how do we determine who is guilty the idea is that after we bring together all these you know we do like a collective blame accounting and we exchange our views about sort of who we have seen not send votes in time and so forth we go and try and find a node as guilty that is majority blamed in a majority of views. Okay so a node will definitely be guilty if it's majority blamed in a majority of views. Why is that so well here's some good news about this right no honest node will ever be found guilty because we said that no honest node will be blamed by other honest nodes in all the synchronous views the synchronous views are the majority and the honest nodes are the majority right so there cannot be an honest node that is majority blamed in majority of views.

The problem with you know just this idea is that you're not guaranteed that there is any one Byzantine node that actually falls under this condition right so we're not sure that we can actually there's actually anybody that we'll be finding guilty with this mechanism but there is you know an extension basically of this intuition this intuition you know holds like roughly morally right there is a way to sort of restrict the views over which we apply this rule in a carefully to a carefully selected subset of views for which we can then give a cute combinatorial argument to guarantee that the nodes are found guilty and the argument is really pretty simple we just don't have time here to talk about it but I encourage you to check it out in the paper it's right in the introduction.

So yeah so that's how we get that main result right we can augment protocols like Tendermint so that they have the typical properties of partially synchronous protocols but also the additional functionality of giving us accountable liveness in majority synchronous execution. So I'll summarize we've talked about the definition of accountable liveness we've shown these two results that you cannot get accountable liveness when f is greater than n over 2 even under synchrony and you cannot get accountable liveness if f is greater than n over 3 in as long as you have to deal with minority synchronous executions on the flip side sort of we have shown the achievability which is that in majority synchronous executions when the adversary is less than half of the validators you can actually get accountable liveness and we can modify any number of standard protocols to achieve this the protocol that we have I would consider it a proof of concept definitely you know it's a cute protocol it works. But definitely much more R&D is needed to sort of streamline it improve its efficiency kind of dock it into the protocols that we would actually be running. But I think yeah the goal here is to kind of provide the framework within which we can sort of reason about mechanisms like inactivity leak.

One thing we haven't talked about but I've briefly mentioned it on the second slide is this question of okay if there is a liveness violation and we go and identify malicious parties how many Byzantine nodes can we actually find guilty whenever there is a liveness violation and in the paper we have upper and lower bounds sort of you know we show that what is sort of the identification budget of our protocol and we also show certain bounds on what you know no other protocol can sort of do better than that and there is a small little gap between the two. So yeah I encourage you to check that out it's figure one in the paper and this is the link to the paper and with that I thank you and I'm open to questions.

## Q&A on Accountable Liveness

**Justin:** Thank you Draim any questions from the audience. One I'll kick it off with one question I guess the construction that you're suggesting involves quite a bit of infrastructure in addition to what we already have is there some sort of small diff to the current logic that we have with the inactivity leak which would improve the status quo without bringing in all of this machinery into consensus.

**Dr. Kim (Joachim):** Yeah I would say we don't know that at the moment like I don't have a protocol like this in mind but also we haven't spent much cycles on this yet so far we've mostly been interested in you know is this possible at all what does it mean to like do this successfully from like a security perspective from like a properties perspective. How to sort of dock that kind of into the like Ethereum's protocol specifically that's still at the very beginning we plan to continue working on that and plan to sort of you know write a follow-up that sort of looks much more into these kind of efficiency questions and in questions like you know how much information do you actually need to identify and leak these parties and you know we have certain information sort of on the beacon chain things like you know we count all the votes there so you know we know which votes are reported there or not so yeah it's unclear at this point.

**Justin:** I guess another question that I have is accountable liveness is not achievable as shown in the slide in situations two and three can these situations be programmatically detected so that we don't penalized honest participants.

**Dr. Kim (Joachim):** No yes no that is that is a challenge yes basically yeah like the moment you know the chain becomes sort of dominated by a majority adversary right like you yeah you know they can go around and if they're really smart and they sort of launch the best attack then you know you rely on sort of additional synchrony assumption of like other people sort of watching the network and sort of knowing what's true right but sort of within kind of this the definition of like what accountable liveness is which is you know you produce these sort of certificates this kind of cryptographic evidence with which you can convince other people we need to make these two assumptions. And you know if somebody shows you such evidence then you can never you can't be sure whether that was produced sort of honestly or maybe one of these properties was sort of broken and that has then allowed this forgery of the cryptographic evidence.

**Terrence:** Yeah so I think today if I remember correctly which I could be wrong right today in Ethereum if you miss proposing a block you don't really get a penalty for that and I think in the context of inactivity leak it only covers attestations it doesn't cover block so in this case in your I guess in your model are you looking at both the block as a message and attestation as a message or just the attestation I guess the question is that what message are we publishing here.

**Dr. Kim (Joachim):** For the purposes of the protocol that we have right it's primarily about the votes. The votes in some sense are I think they're the more fundamental thing with which the adversary can sort of prevent liveness right like you know the adversary proposers can just not propose blocks right then maybe you should still have some sort of a mechanism to go after them that's good but that is not sort of a that doesn't solve the problem all the way in some sense right that's basically on a heuristic level the hard part is really you know what happens if you have honest proposers and they do produce blocks and nobody votes for them right because if you know if it the adversary proposers they're an annoyance they're not great you should punish them if they don't produce a block but they can sort of halt progress sort of indefinitely because quite frequently there will be honest proposers right and so if the adversary wants to hold back progress indefinitely it needs to sort of stop the honest proposers from going through and the honest proposers are you know it can only hold them up by not voting basically so for the purposes of like this this kind of strong notion of like punishing kind of liveness violations that is sort of the critical part not kind of the missing proposal.

I think the other aspect to this is perhaps that you know the way you could see it is that an adversary proposer can always just propose an empty block right so just the fact that like the fact that there are blocks right is not enough to give you liveness right and so it's hard to you know right now we wouldn't punish them for proposing like an empty block or a block that sort of misses transactions that we think should have been there or something like that right so this kind of yeah slashing or punishing the proposer I think of as a heuristic the sort of really fundamental problem is what do you do with the adversary if it keeps not voting for legitimate proposals made by honest parties.

## Closing Remarks

**Justin:** Okay we're past the 1 hour and a half we're about 15 minutes over I'd like to thank all of the speakers again and yeah congratulations for making through almost two hours of beam call and yeah the next call will be on rainbow staking thank you so much everyone have a great day bye.